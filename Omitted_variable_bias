import numpy as np
import statsmodels.api as sm

# Set seed for reproducibility
np.random.seed(1234)

# Parameters
n = 1000  # Sample size
B0, B1, B2, B3 = 1, 2, 3, 4  # True coefficients

# Simulate X3 and derive X1 = log(X3)
X3 = np.random.exponential(scale=2, size=n)  # X3 ~ Exponential(2)
X1 = np.log(X3)  # X1 = log(X3)
X2 = np.random.normal(loc=5, scale=1, size=n)  # X2 ~ N(5, 1)

# True model: y = B0 + B1*X1 + B2*X2 + B3*X3 + epsilon
epsilon = np.random.normal(loc=0, scale=1, size=n)  # epsilon ~ N(0, 1)
y = B0 + B1 * X1 + B2 * X2 + B3 * X3 + epsilon

# Estimated model (omitting X3)
X = np.column_stack((np.ones(n), X1, X2))  # Design matrix with intercept, X1, X2
model = sm.OLS(y, X).fit()  # Fit the model
beta_hat = model.params  # Estimated coefficients

# Theoretical bias
# Auxiliary regression: X3 = gamma0 + gamma1*X1 + gamma2*X2 + error
X_aux = np.column_stack((np.ones(n), X1, X2))
aux_model = sm.OLS(X3, X_aux).fit()
gamma1, gamma2 = aux_model.params[1], aux_model.params[2]

# Theoretical bias formulas
bias_B0 = B3 * (np.mean(X3) - gamma1 * np.mean(X1) - gamma2 * np.mean(X2))
bias_B1 = B3 * (np.cov(X1, X3)[0, 1] / np.var(X1))
bias_B2 = B3 * (np.cov(X2, X3)[0, 1] / np.var(X2))

# Empirical bias (difference between estimated and true coefficients)
empirical_bias_B0 = beta_hat[0] - B0
empirical_bias_B1 = beta_hat[1] - B1
empirical_bias_B2 = beta_hat[2] - B2

# Variance of the estimated coefficients
var_B0, var_B1, var_B2 = model.bse[0]**2, model.bse[1]**2, model.bse[2]**2

# Print results
print("Theoretical Bias:")
print(f"Bias(B0): {bias_B0:.4f}, Bias(B1): {bias_B1:.4f}, Bias(B2): {bias_B2:.4f}")
print("\nEmpirical Bias:")
print(f"Bias(B0): {empirical_bias_B0:.4f}, Bias(B1): {empirical_bias_B1:.4f}, Bias(B2): {empirical_bias_B2:.4f}")
print("\nVariance of Estimated Coefficients:")
print(f"Var(B0): {var_B0:.4f}, Var(B1): {var_B1:.4f}, Var(B2): {var_B2:.4f}")
